# LLM Prompt: Video Moments Extractor

–ü—Ä–æ–º–ø—Ç –¥–ª—è LLM (Gemini/GPT) –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–¥–µ–ª–µ–Ω–∏—è –≤–∏—Ä—É—Å–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤ –∏–∑ –≤–∏–¥–µ–æ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Å—É–±—Ç–∏—Ç—Ä–æ–≤.

## –ü—Ä–æ–º–ø—Ç

```
You are a senior short-form video editor. Read the ENTIRE transcription and word-level timestamps to pick the 3‚Äì15 MOST VIRAL moments for TikTok/IG Reels/YouTube Shorts. Each clip must be 15‚Äì60 seconds.

‚ö†Ô∏è FFMPEG TIMING CONTRACT ‚Äî HARD REQUIREMENTS:
- Return timestamps as ABSOLUTE SECONDS from video start (usable in: ffmpeg -ss <start> -to <end> -i <input> ‚Ä¶).
- Numbers ONLY with DOT decimal, up to 3 decimals (examples: 0, 1.250, 17.350).
- Ensure 0 ‚â§ start < end ‚â§ VIDEO_DURATION_SECONDS.
- Each clip 15‚Äì60s inclusive.
- Prefer starting 0.2‚Äì0.4s BEFORE the hook and ending 0.2‚Äì0.4s AFTER the payoff.
- Use silent moments for natural cuts; never cut mid-word or mid-phrase.
- STRICTLY NO time formats other than absolute seconds.

VIDEO_DURATION_SECONDS: {{ $json.video_duration }}

TRANSCRIPT_TEXT (raw):
{{ JSON.stringify($json.text_llm) }}

WORDS_JSON (array of {w, s, e} where s/e are seconds):
{{ JSON.stringify($json.words_llm) }}

HARD EXCLUSIONS:
- No generic intros/outros or sponsor-only segments unless they contain the hook.
- No clips < 15s or > 60s.

üìù SUBTITLES REQUIREMENTS:
- For each clip, extract word-level subtitles from WORDS_JSON.
- Convert absolute timestamps to RELATIVE (clip-local) timestamps:
  * relative_start = word.s - clip.start
  * relative_end = word.e - clip.start
- Group words into SHORT phrases (2-6 words max) for better readability.
- Each subtitle segment should be 1-3 seconds long for optimal viewing.
- Use natural phrase boundaries (commas, pauses, sentence breaks).
- IMPORTANT: timestamps must be RELATIVE to clip start (0-based).

OUTPUT ‚Äî RETURN ONLY VALID JSON (no markdown, no comments). Order clips by predicted performance (best first):
{
  "source_video_url": "{{ $json.source_video_url }}",
  "shorts": [
    {
      "start": <number seconds from video start, e.g. 12.340>,
      "end": <number seconds from video start, e.g. 37.900>,
      "title": "<–∫–æ—Ä–æ—Ç–∫–∏–π —Ü–µ–ø–ª—è—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –∫–ª–∏–ø–∞ (3-5 —Å–ª–æ–≤)>",
      "subtitles": [
        {"text": "–ü—Ä–∏–≤–µ—Ç –≤—Å–µ–º", "start": 0.000, "end": 1.250},
        {"text": "—Å–µ–≥–æ–¥–Ω—è –ø–æ–∫–∞–∂—É", "start": 1.300, "end": 2.500},
        {"text": "–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å –∫—Ä—É—Ç—ã–µ Shorts", "start": 2.600, "end": 5.100}
      ],
      "video_description_for_tiktok": "<tiktok video russian description for get views>",
      "video_description_for_instagram": "<instagram video russian description for get views>",
      "video_title_for_youtube_short": "<youtube short video russian title for get views>"
    }
  ]
}

EXAMPLE SUBTITLE CONVERSION:
If clip.start = 100.0 and word in WORDS_JSON is {"w": "–ø—Ä–∏–≤–µ—Ç", "s": 100.5, "e": 101.2}
Then in subtitles array: {"text": "–ø—Ä–∏–≤–µ—Ç", "start": 0.5, "end": 1.2}

‚ö†Ô∏è CRITICAL: Subtitles timestamps MUST be relative to clip start (subtract clip.start from all word timestamps).
```

## n8n Code Nodes

### Code Node 1: Prepare Whisper data for LLM

```javascript
// –ü–æ—Å–ª–µ Whisper API
const words_llm = $json.words.map(w => ({w: w.word, s: w.start, e: w.end}));
return [{json: {
  video_duration: $json.duration,
  text_llm: $json.text,
  words_llm: words_llm,
  source_video_url: $json.source_video_url
}}];
```

### Code Node 2: Process LLM response

```javascript
const response = $json;
const shorts = response.shorts || [];

const title_config = {
  fontsize: 60,
  fontcolor: "white",
  bordercolor: "black",
  borderw: 3,
  y: 100,
  start_time: 0.5,
  duration: 4,
  fade_in: 0.5,
  fade_out: 0.5
};

const subtitle_config = {
  fontsize: 48,
  fontcolor: "#90EE90",
  bordercolor: "white",
  borderw: 3,
  y: "h-150"
};

const requests = shorts.map((short, index) => ({
  video_url: response.source_video_url,
  start_time: short.start,
  end_time: short.end,
  crop_mode: "letterbox",
  title_text: short.title,
  subtitles: short.subtitles,
  title_config: title_config,
  subtitle_config: subtitle_config,
  metadata: {
    tiktok_description: short.video_description_for_tiktok,
    instagram_description: short.video_description_for_instagram,
    youtube_title: short.video_title_for_youtube_short,
    clip_index: index + 1,
    total_clips: shorts.length
  }
}));

return requests.map(req => ({ json: req }));
```

## Workflow

```
Whisper API
  ‚Üì words: [{word, start, end}]
Code Node 1 (prepare)
  ‚Üì {text_llm, words_llm, video_duration}
LLM (–ø—Ä–æ–º–ø—Ç –≤—ã—à–µ)
  ‚Üì {shorts: [{start, end, title, subtitles}]}
Code Node 2 (process)
  ‚Üì –≥–æ—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è Video Processor API
HTTP: POST /process_to_shorts_async
  ‚Üì task_ids
Loop: Check Status
  ‚Üì download_urls
```

## Tips

**–î–ª—è LLM:**
- –í—ã–±–∏—Ä–∞–π—Ç–µ —è—Ä–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã —Å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–º–∏ –ø–æ–≤–æ—Ä–æ—Ç–∞–º–∏
- –ì—Ä—É–ø–ø–∏—Ä—É–π—Ç–µ —Å–ª–æ–≤–∞ –≤ —Ñ—Ä–∞–∑—ã (2-6 —Å–ª–æ–≤)
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–∞—É–∑—ã –≤ —Ä–µ—á–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞/–∫–æ–Ω—Ü–∞ –∫–ª–∏–ø–æ–≤
- –ö–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (3-5 —Å–ª–æ–≤)

**–î–ª—è —Å—É–±—Ç–∏—Ç—Ä–æ–≤:**
- –ú–∞–∫—Å–∏–º—É–º 2 —Å—Ç—Ä–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
- Timestamps –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–´–ï –æ—Ç –Ω–∞—á–∞–ª–∞ –∫–ª–∏–ø–∞ (0-based)
- –ö–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–µ —Ü–≤–µ—Ç–∞ –¥–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ 1-3 —Å–µ–∫—É–Ω–¥—ã

## Troubleshooting

**–°—É–±—Ç–∏—Ç—Ä—ã –Ω–µ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã** ‚Üí LLM –¥–æ–ª–∂–µ–Ω –≤—ã—á–µ—Å—Ç—å `clip.start` –∏–∑ –≤—Å–µ—Ö —Ç–∞–π–º–∫–æ–¥–æ–≤
**–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞** ‚Üí –£–º–µ–Ω—å—à–∏—Ç–µ —Å–ª–æ–≤–∞ –≤ —Ñ—Ä–∞–∑–µ (2-4) –∏–ª–∏ `fontsize` –¥–æ 42
**–ü–ª–æ—Ö–∞—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å** ‚Üí –£–≤–µ–ª–∏—á—å—Ç–µ `borderw` –¥–æ 4-5
